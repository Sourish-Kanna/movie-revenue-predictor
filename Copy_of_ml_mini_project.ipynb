{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas joblib\n",
        "!pip install scikit-learn==1.7.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-ZdBgLfiGaIC",
        "outputId": "445f62e7-9ea3-4386-8aab-aea0349e867a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting scikit-learn==1.7.2\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQn15KDZEX5H",
        "outputId": "9fd026e6-fa42-4900-bd3b-ec6b88dfc17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Model Performance:\n",
            "Accuracy: 0.85\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.91      0.91      0.91        34\n",
            "\n",
            "    accuracy                           0.85        41\n",
            "   macro avg       0.74      0.74      0.74        41\n",
            "weighted avg       0.85      0.85      0.85        41\n",
            "\n",
            "\n",
            "Model saved to 'movie_predictor.joblib'. Download this file for your backend.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Load Data (Upload movie_dataset.csv to Colab) ---\n",
        "try:\n",
        "    df = pd.read_csv('movie_dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'movie_dataset.csv' not found. Please upload the file to your Colab session.\")\n",
        "    # Exit if the file is not found\n",
        "    exit()\n",
        "\n",
        "# --- 2. Data Cleaning and Preprocessing ---\n",
        "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
        "df['box_office'] = pd.to_numeric(df['box_office'], errors='coerce')\n",
        "df.dropna(subset=['budget', 'box_office'], inplace=True)\n",
        "df = df[df['budget'] > 0].copy()\n",
        "\n",
        "df['success'] = (df['box_office'] > df['budget']).astype(int)\n",
        "\n",
        "def convert_runtime_to_minutes(runtime_str):\n",
        "    if pd.isna(runtime_str) or runtime_str == 'Not Available':\n",
        "        return np.nan\n",
        "\n",
        "    parts = runtime_str.split()\n",
        "    total_minutes = 0\n",
        "    if len(parts) >= 2 and 'h' in parts[0]:\n",
        "        total_minutes += int(parts[0].replace('h', '')) * 60\n",
        "    if len(parts) >= 2 and 'm' in parts[1]:\n",
        "        total_minutes += int(parts[1].replace('m', ''))\n",
        "    return total_minutes\n",
        "\n",
        "df['run_time_minutes'] = df['run_time'].apply(convert_runtime_to_minutes)\n",
        "\n",
        "# --- 3. Feature Selection and Splitting Data ---\n",
        "features = ['year', 'rating', 'genre', 'run_time_minutes', 'budget']\n",
        "X = df[features]\n",
        "y = df['success']\n",
        "X.dropna(inplace=True)\n",
        "y = y[X.index]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- 4. Building the Model Pipeline ---\n",
        "categorical_features = ['rating', 'genre']\n",
        "numerical_features = ['year', 'run_time_minutes', 'budget']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# --- 5. Train and Evaluate the Model ---\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# --- 6. Save the Trained Model ---\n",
        "model_filename = 'movie_predictor.joblib'\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(f\"\\nModel saved to '{model_filename}'. Download this file for your backend.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor  # Changed to Regressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score  # New evaluation metrics\n",
        "import joblib\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Load Data (Upload movie_dataset.csv to Colab) ---\n",
        "try:\n",
        "    df = pd.read_csv('movie_dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "\n",
        "    # --- 2. Data Cleaning and Preprocessing ---\n",
        "    df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
        "    df['box_office'] = pd.to_numeric(df['box_office'], errors='coerce')\n",
        "    df.dropna(subset=['budget', 'box_office'], inplace=True)\n",
        "    df = df[df['budget'] > 0].copy()\n",
        "\n",
        "    # The target variable is now 'box_office'\n",
        "    # df['success'] = (df['box_office'] > df['budget']).astype(int) # This line is removed.\n",
        "\n",
        "    def convert_runtime_to_minutes(runtime_str):\n",
        "        if pd.isna(runtime_str) or runtime_str == 'Not Available':\n",
        "            return np.nan\n",
        "\n",
        "        parts = runtime_str.split()\n",
        "        total_minutes = 0\n",
        "        if len(parts) >= 2 and 'h' in parts[0]:\n",
        "            total_minutes += int(parts[0].replace('h', '')) * 60\n",
        "        if len(parts) >= 2 and 'm' in parts[1]:\n",
        "            total_minutes += int(parts[1].replace('m', ''))\n",
        "        return total_minutes\n",
        "\n",
        "    df['run_time_minutes'] = df['run_time'].apply(convert_runtime_to_minutes)\n",
        "\n",
        "    # --- 3. Feature Selection and Splitting Data ---\n",
        "    features = ['year', 'rating', 'genre', 'run_time_minutes', 'budget']\n",
        "    X = df[features]\n",
        "    y = df['box_office']  # The target is now the box office amount\n",
        "    X.dropna(inplace=True)\n",
        "    y = y[X.index]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # --- 4. Building the Model Pipeline ---\n",
        "    categorical_features = ['rating', 'genre']\n",
        "    numerical_features = ['year', 'run_time_minutes', 'budget']\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', 'passthrough', numerical_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Changed the classifier to a regressor\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "    # --- 5. Train and Evaluate the Model ---\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\nModel Performance:\")\n",
        "    print(f\"Mean Squared Error: {mse:,.2f}\")\n",
        "    print(f\"R-squared: {r2:.2f}\")\n",
        "\n",
        "    # --- 6. Save the Trained Model ---\n",
        "    model_filename = 'movie_revenue_predictor.joblib'  # Changed filename\n",
        "    joblib.dump(model, model_filename)\n",
        "\n",
        "    print(f\"\\nModel saved to '{model_filename}'. Download this file for your backend.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'movie_dataset.csv' not found. Please upload the file to your Colab session.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxyOd7t_EiPW",
        "outputId": "dedcab83-675f-429d-f406-0610e593fd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Model Performance:\n",
            "Mean Squared Error: 23,580,549,535,182,736.00\n",
            "R-squared: 0.71\n",
            "\n",
            "Model saved to 'movie_revenue_predictor.joblib'. Download this file for your backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56fb0c8c",
        "outputId": "bb600811-2be1-424e-9538-b3ab5a82b696"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "try:\n",
        "    df = pd.read_csv('movie_dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "\n",
        "    # --- 2. Data Cleaning and Preprocessing ---\n",
        "    df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
        "    df['box_office'] = pd.to_numeric(df['box_office'], errors='coerce')\n",
        "    # Keep rows with valid budget and box_office for potential use as features\n",
        "    df.dropna(subset=['budget', 'box_office'], inplace=True)\n",
        "    df = df[df['budget'] > 0].copy()\n",
        "\n",
        "    def convert_runtime_to_minutes(runtime_str):\n",
        "        if pd.isna(runtime_str) or runtime_str == 'Not Available':\n",
        "            return np.nan\n",
        "\n",
        "        parts = runtime_str.split()\n",
        "        total_minutes = 0\n",
        "        if len(parts) >= 2 and 'h' in parts[0]:\n",
        "            total_minutes += int(parts[0].replace('h', '')) * 60\n",
        "        if len(parts) >= 2 and 'm' in parts[1]:\n",
        "            total_minutes += int(parts[1].replace('m', ''))\n",
        "        return total_minutes\n",
        "\n",
        "    df['run_time_minutes'] = df['run_time'].apply(convert_runtime_to_minutes)\n",
        "\n",
        "    # --- 3. Feature Selection and Splitting Data ---\n",
        "    # Using relevant features to predict rank\n",
        "    features = ['year', 'rating', 'genre', 'run_time_minutes', 'budget', 'box_office']\n",
        "    X = df[features]\n",
        "    y = df['rank']  # The target is now the movie rank\n",
        "\n",
        "    X.dropna(inplace=True)\n",
        "    y = y[X.index] # Ensure target variable aligns with features after dropping NaNs\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # --- 4. Building the Model Pipeline ---\n",
        "    categorical_features = ['rating', 'genre']\n",
        "    numerical_features = ['year', 'run_time_minutes', 'budget', 'box_office']\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', 'passthrough', numerical_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "        ])\n",
        "\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "    # --- 5. Train and Evaluate the Model ---\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse) # Calculate Root Mean Squared Error\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\nModel Performance:\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "    print(f\"R-squared: {r2:.2f}\")\n",
        "\n",
        "    # --- 6. Save the Trained Model (Optional) ---\n",
        "    model_filename = 'movie_rank_predictor.joblib'\n",
        "    joblib.dump(model, model_filename)\n",
        "    print(f\"\\nModel saved to '{model_filename}'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'movie_dataset.csv' not found. Please upload the file to your Colab session.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Model Performance:\n",
            "Mean Squared Error (MSE): 502.04\n",
            "Root Mean Squared Error (RMSE): 22.41\n",
            "R-squared: 0.89\n",
            "\n",
            "Model saved to 'movie_rank_predictor.joblib'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33d21a17"
      },
      "source": [
        "Based on the columns available in the `movie_dataset.csv` and the types of data they contain, here are some machine learning models you could build:\n",
        "\n",
        "*   **Predicting Box Office Success (Classification):** As you've already done, you can build a binary classification model to predict if a movie will be a financial success (e.g., box office > budget). You can use algorithms like:\n",
        "    *   Logistic Regression\n",
        "    *   Support Vector Machines (SVM)\n",
        "    *   Decision Trees\n",
        "    *   Random Forests (which you've used)\n",
        "    *   Gradient Boosting Machines (like LightGBM or XGBoost)\n",
        "*   **Predicting Box Office Revenue (Regression):** You can build a regression model to predict the actual box office revenue a movie will generate. You can use algorithms like:\n",
        "    *   Linear Regression\n",
        "    *   Ridge, Lasso, or Elastic Net Regression\n",
        "    *   Support Vector Regression (SVR)\n",
        "    *   Decision Tree Regression\n",
        "    *   Random Forest Regressor (which you've used)\n",
        "    *   Gradient Boosting Regressors\n",
        "*   **Predicting Movie Rating:** You could potentially treat the rating as a classification problem (predicting a rating category) or a regression problem (predicting the numerical rating).\n",
        "    *   **Classification (Rating Categories):** Use classifiers listed above.\n",
        "    *   **Regression (Numerical Rating):** Use regressors listed above.\n",
        "*   **Predicting Genre:** If you wanted to predict the genre based on other features (though this might be less practical as genre is usually known beforehand), you could treat this as a multi-class classification problem using algorithms like:\n",
        "    *   Multinomial Logistic Regression\n",
        "    *   Decision Trees\n",
        "    *   Random Forests\n",
        "    *   Naive Bayes\n",
        "*   **Recommending Movies:** Based on features like genre, rating, cast, directors, etc., you could build a recommendation system. This could involve various techniques, including:\n",
        "    *   Collaborative Filtering\n",
        "    *   Content-Based Filtering\n",
        "    *   Matrix Factorization (e.g., using techniques like Singular Value Decomposition)\n",
        "\n",
        "To build these models, you would typically follow these general steps:\n",
        "\n",
        "1.  **Load the data:** Read the `movie_dataset.csv` file.\n",
        "2.  **Explore and preprocess the data:** Handle missing values, convert data types, and encode categorical features (like 'rating', 'genre', 'casts', 'directors', 'writers').\n",
        "3.  **Feature Engineering:** Create new features from existing ones if needed (e.g., extracting the number of genres, or analyzing cast/director/writer popularity).\n",
        "4.  **Split the data:** Divide the data into training and testing sets.\n",
        "5.  **Choose a model:** Select an appropriate machine learning algorithm based on the problem you are trying to solve (classification, regression, etc.).\n",
        "6.  **Train the model:** Fit the model to the training data.\n",
        "7.  **Evaluate the model:** Assess the model's performance using relevant metrics.\n",
        "8.  **Tune hyperparameters:** Optimize the model's parameters for better performance.\n",
        "9.  **Make predictions:** Use the trained model to make predictions on new, unseen data.\n",
        "\n",
        "The specific model you choose and how you preprocess the data will depend on the exact problem you want to solve and the desired outcome."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "import numpy as np\n",
        "import ast  # Library to safely evaluate string representations of Python literals\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Load the New, Unbiased Dataset ---\n",
        "try:\n",
        "    df = pd.read_csv('tmdb_5000_movies.csv')\n",
        "    print(\"TMDB 5000 dataset loaded successfully.\")\n",
        "\n",
        "    # --- 2. Advanced Data Cleaning and Preparation ---\n",
        "    print(\"Starting data cleaning and preparation...\")\n",
        "\n",
        "    # A. Handle missing financial data (treat 0 as missing)\n",
        "    df['budget'].replace(0, np.nan, inplace=True)\n",
        "    df['revenue'].replace(0, np.nan, inplace=True)\n",
        "    df.dropna(subset=['budget', 'revenue'], inplace=True)\n",
        "    print(f\"Removed rows with missing financial data. Shape is now: {df.shape}\")\n",
        "\n",
        "    # B. Parse the JSON 'genres' column\n",
        "    def parse_json_column(column_str):\n",
        "        try:\n",
        "            items = ast.literal_eval(column_str)\n",
        "            names = [item['name'] for item in items]\n",
        "            # Handle cases where genres might be empty\n",
        "            if not names:\n",
        "                return np.nan\n",
        "            return ','.join(names)\n",
        "        except (ValueError, SyntaxError, TypeError):\n",
        "            return np.nan # Return NaN if parsing fails\n",
        "\n",
        "    df['genres'] = df['genres'].apply(parse_json_column)\n",
        "\n",
        "    # C. Handle release date\n",
        "    # Some release dates might be malformed, so use errors='coerce'\n",
        "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
        "    df.dropna(subset=['release_date', 'genres', 'runtime'], inplace=True)\n",
        "    df['year'] = df['release_date'].dt.year\n",
        "\n",
        "    # D. Rename columns to match the original script's expectations\n",
        "    df.rename(columns={\n",
        "        'revenue': 'box_office',\n",
        "        'vote_average': 'rating',\n",
        "        'runtime': 'run_time_minutes' # Runtime is already in minutes, just needs renaming\n",
        "    }, inplace=True)\n",
        "\n",
        "    print(\"Data cleaning complete.\")\n",
        "\n",
        "    # --- 3. Feature Selection and Splitting Data ---\n",
        "    # Select the final features for the model\n",
        "    features = ['year', 'rating', 'genres', 'run_time_minutes', 'budget']\n",
        "    X = df[features]\n",
        "    y = df['box_office']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(f\"Data split into training ({X_train.shape[0]} rows) and testing ({X_test.shape[0]} rows) sets.\")\n",
        "\n",
        "    # --- 4. Building the Model Pipeline (same as before) ---\n",
        "    categorical_features = ['genres'] # Rating is now treated as a numerical feature\n",
        "    numerical_features = ['year', 'rating', 'run_time_minutes', 'budget']\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', 'passthrough', numerical_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "        ])\n",
        "\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "    print(\"Model pipeline created.\")\n",
        "\n",
        "    # --- 5. Train and Evaluate the New Model ---\n",
        "    print(\"Training the new model...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Model training complete.\")\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\n--- New Model Performance ---\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:,.2f}\")\n",
        "    print(f\"R-squared (R²): {r2:.2f}\")\n",
        "\n",
        "    # --- 6. Save the Newly Trained Model ---\n",
        "    model_filename = 'movie_revenue_predictor.joblib'\n",
        "    joblib.dump(model, model_filename)\n",
        "\n",
        "    print(f\"\\nNew, improved model saved to '{model_filename}'.\")\n",
        "    print(\"You can now replace the old model file in your Flask app with this new one.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'tmdb_5000_movies.csv' not found. Please ensure it's uploaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W66dptgjaJms",
        "outputId": "44903a79-e1d7-47d7-efeb-65248332cf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TMDB 5000 dataset loaded successfully.\n",
            "Starting data cleaning and preparation...\n",
            "Removed rows with missing financial data. Shape is now: (3229, 20)\n",
            "Data cleaning complete.\n",
            "Data split into training (2582 rows) and testing (646 rows) sets.\n",
            "Model pipeline created.\n",
            "Training the new model...\n",
            "Model training complete.\n",
            "\n",
            "--- New Model Performance ---\n",
            "Mean Squared Error (MSE): 20,013,921,597,324,100.00\n",
            "R-squared (R²): 0.60\n",
            "\n",
            "New, improved model saved to 'movie_revenue_predictor.joblib'.\n",
            "You can now replace the old model file in your Flask app with this new one.\n"
          ]
        }
      ]
    }
  ]
}